{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: lru-dict 1.3.0\n",
      "Uninstalling lru-dict-1.3.0:\n",
      "  Successfully uninstalled lru-dict-1.3.0\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting lru-dict\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ca/b9/9db79780c8a3cfd66bba6847773061e5cf8a3746950273b9985d47bbfe53/lru_dict-1.3.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Installing collected packages: lru-dict\n",
      "Successfully installed lru-dict-1.3.0\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pycurl in /hpc2hdd/home/tianlangxue/anaconda3/envs/OPT/lib/python3.12/site-packages (7.45.3)\n",
      "arch: invalid option -- 'a'\n",
      "Try 'arch --help' for more information.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pycapnp in /hpc2hdd/home/tianlangxue/anaconda3/envs/OPT/lib/python3.12/site-packages (2.0.0)\n",
      "/bin/bash: line 1: brew: command not found\n",
      "/bin/bash: line 1: brew: command not found\n"
     ]
    }
   ],
   "source": [
    "#On my mac, it was a real pain to get the comma2k19 dataset to work. I had to do the following but you might not have to:\n",
    "\n",
    "!pip uninstall lru-dict -y\n",
    "!ARCHFLAGS=\"-arch arm64\" pip install lru-dict --compile --no-cache-dir\n",
    "!set -x PYCURL_SSL_LIBRARY openssl\n",
    "!export PYCURL_SSL_LIBRARY=openssl\n",
    "!export LDFLAGS=-L/usr/local/opt/openssl/lib\n",
    "!export CPPFLAGS=-I/usr/local/opt/openssl/include\n",
    "!ARCHFLAGS=\"-arch arm64\" pip install pycurl --no-cache-dir\n",
    "!arch -arm64 pip install pycurl --compile --no-cache-dir\n",
    "!ARCHFLAGS=\"-arch arm64\" pip install pycapnp\n",
    "!brew uninstall openssl\n",
    "!brew install https://github.com/tebelorg/Tump/releases/download/v1.0.0/openssl.rb\n",
    "# !brew install https://github.com/tebelorg/Tump/releases/download/v1.0.0/openssl.rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import platform\n",
    "platform.architecture()\n",
    "sys.path.append(\"/hpc2hdd/home/tianlangxue/XAI4AD/openpilot\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kj/filesystem-disk-unix.c++:1734: warning: PWD environment variable doesn't match current directory; pwd = /hpc2hdd/home/tianlangxue\n"
     ]
    }
   ],
   "source": [
    "from tools.lib.logreader import LogReader\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tools.lib.framereader import FrameReader\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sensorEventsDEPRECATED',\n",
       " 'controlsState',\n",
       " 'sendcan',\n",
       " 'carState',\n",
       " 'carControl',\n",
       " 'logMessage',\n",
       " 'can',\n",
       " 'longitudinalPlan',\n",
       " 'can',\n",
       " 'sendcan',\n",
       " 'sensorEventsDEPRECATED',\n",
       " 'sensorEventsDEPRECATED',\n",
       " 'carState',\n",
       " 'controlsState',\n",
       " 'carControl',\n",
       " 'logMessage',\n",
       " 'logMessage',\n",
       " 'logMessage',\n",
       " 'can',\n",
       " 'roadEncodeIdx',\n",
       " 'roadEncodeIdx',\n",
       " 'longitudinalPlan',\n",
       " 'controlsState',\n",
       " 'sendcan',\n",
       " 'carState',\n",
       " 'carControl',\n",
       " 'sensorEventsDEPRECATED',\n",
       " 'can',\n",
       " 'logMessage',\n",
       " 'logMessage',\n",
       " 'radarState',\n",
       " 'liveTracks',\n",
       " 'can',\n",
       " 'sensorEventsDEPRECATED',\n",
       " 'liveLongitudinalMpcDEPRECATED',\n",
       " 'can',\n",
       " 'longitudinalPlan',\n",
       " 'liveLongitudinalMpcDEPRECATED',\n",
       " 'sendcan',\n",
       " 'sensorEventsDEPRECATED',\n",
       " 'sensorEventsDEPRECATED',\n",
       " 'sensorEventsDEPRECATED',\n",
       " 'controlsState',\n",
       " 'carState',\n",
       " 'carControl',\n",
       " 'can',\n",
       " 'roadCameraState',\n",
       " 'sensorEventsDEPRECATED',\n",
       " 'sensorEventsDEPRECATED',\n",
       " 'sensorEventsDEPRECATED']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_segment = '/hpc2hdd/home/tianlangxue/XAI4AD/comma2k19/Example_1/b0c9d2329ad1606b|2018-08-02--08-34-47/40/'\n",
    "lr = LogReader(example_segment + 'raw_log.bz2')\n",
    "# make list of logs\n",
    "logs = list(lr)\n",
    "[l.which() for l in logs[:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extract frames from the video with framereader\n",
    "# from openpilot tools, we look at frame 600\n",
    "frame_index = 600\n",
    "\n",
    "fr = FrameReader(example_segment + 'video.hevc')\n",
    "#figsize(12,12)\n",
    "#imshow(fr.get(frame_index, pix_fmt='rgb24')[0]);\n",
    "#title('Frame 600 extracted from video with FrameReader', fontsize=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(p):\n",
    "    frame_reader = FrameReader(p+'/video.hevc')\n",
    "    logs = list(LogReader(p + '/raw_log.bz2'))\n",
    "\n",
    "    angle = np.array([l.carState.steeringAngleDeg for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    time = np.array([l.logMonoTime for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    vEgo = np.array([l.carState.vEgo for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    gas = np.array([l.carState.gas for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    brake = np.array([l.carState.brake for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    gps_times = np.load(p + '/global_pose/frame_gps_times')\n",
    "    times = np.load(p + '/global_pose/frame_times')\n",
    "    gas = np.array([l.carState.gas for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    gaspressed = np.array([l.carState.gasPressed for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    brake = np.array([l.carState.brake for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    brake_pressed = np.array([l.carState.brakePressed for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "\n",
    "    enabled = np.array([l.carState.cruiseState.enabled for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    speed = np.array([l.carState.cruiseState.speed for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    speedOffset = np.array([l.carState.cruiseState.speedOffset for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    standstill = np.array([l.carState.cruiseState.standstill for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    nonAdaptive = np.array([l.carState.cruiseState.nonAdaptive for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    speedCluster = np.array([l.carState.cruiseState.speedCluster for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    \n",
    "    leftBlinker = np.array([l.carState.leftBlinker for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    rightBlinker = np.array([l.carState.rightBlinker for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    #print(frame_reader.frame_count, gps_times.shape, times.shape)\n",
    "    #print([l.carState for l in logs if l.which() == \"carState\"][0])\n",
    "    #print([l.radarState for l in logs if l.which() == \"radarState\"][0])\n",
    "\n",
    "    dist = np.array([l.radarState.leadOne.dRel for l in logs if l.which() == \"radarState\"])[1::5]\n",
    "    if ((vEgo == 0).mean() > 0.2) or ((dist == 0).mean() > 0.2) or len(dist) <=230:\n",
    "        return None\n",
    "    images = []\n",
    "    l = list(range(frame_reader.frame_count))\n",
    "    if len(l) > 245:\n",
    "        l = l[1::5]\n",
    "    for idx in list(range(frame_reader.frame_count))[1::5]:\n",
    "        image = np.array(frame_reader.get(idx, pix_fmt='rgb24')[0], dtype=np.float64)\n",
    "        image = cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        images.append(image)\n",
    "    steady_state = ~gaspressed & ~brake_pressed & ~leftBlinker & ~rightBlinker\n",
    "    last_idx = 0\n",
    "    desired_gap = np.zeros(steady_state.shape)\n",
    "\n",
    "    for i in range(len(steady_state)-1):\n",
    "        if steady_state[i] == True:\n",
    "            desired_gap[last_idx:i] = int(dist[i])\n",
    "            last_idx = i\n",
    "\n",
    "    sample = {\n",
    "        'image': images,\n",
    "        \"CruiseStateenabled\": enabled, \n",
    "        \"CruiseStatespeed\": speed, \n",
    "        \"CruiseStatespeedOffset\": speedOffset,\n",
    "        \"CruiseStatestandstill\": standstill, \n",
    "        \"CruiseStatenonAdaptive\": nonAdaptive, \n",
    "        \"CruiseStatespeedCluster\": speedCluster, \n",
    "        'leftBlinker': leftBlinker, \n",
    "        'rightBlinker': rightBlinker, \n",
    "        \"gas\": gas, \n",
    "        \"gaspressed\": gaspressed, \n",
    "        \"brake\": brake, \n",
    "        \"brakepressed\": brake_pressed, \n",
    "        'angle': angle, \n",
    "        'time': time, \n",
    "        'gas': gas, \n",
    "        'vEgo': vEgo, \n",
    "        'brake': brake, \n",
    "        'dist': dist, \n",
    "        'desired_dist': desired_gap,\n",
    "        } \n",
    "    return sample if not ((desired_gap == 0).mean() > 0.2) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_h5py(i, sample, h):\n",
    "    group = h.create_group(str(i))\n",
    "    for col in sample.keys():\n",
    "            dt = np.float32 if col != 'image' else int#\n",
    "            dataset_name = col #groups are divided by '/'\n",
    "            a = list(sample[col])\n",
    "            group.create_dataset(dataset_name, data = np.asarray(a, dtype=dt),\n",
    "                    #compression_opts=9,\n",
    "                    #chunks=(164, 20, 20, 3),\n",
    "                    compression='lzf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_type = \"train\"\n",
    "main_dir='/hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data/Chunk_2/'\n",
    "hdf5_filename = \"gas_and_brake_train_comma_chunk_2_w_imgs.hfd5\"\n",
    "h_train = h5py.File(hdf5_filename, 'w')\n",
    "hdf5_filename = \"gas_and_brake_val_comma_chunk_2_w_imgs.hfd5\"\n",
    "h_val = h5py.File(hdf5_filename, 'w')\n",
    "hdf5_filename = \"gas_and_brake_test_comma_chunk_2_w_imgs.hfd5\"\n",
    "h_test = h5py.File(hdf5_filename, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [59:50, 170.97s/it]\n"
     ]
    }
   ],
   "source": [
    "for j, drive_sequence_path in tqdm(enumerate(os.listdir(main_dir))):\n",
    "    if '.DS_Store ' in drive_sequence_path or not os.path.isdir(main_dir+\"/\"+drive_sequence_path): continue\n",
    "    min_sequence_paths = os.listdir(main_dir+\"/\"+drive_sequence_path)\n",
    "    if len(min_sequence_paths) < 3: continue\n",
    "    min_sequence_path_test = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence_paths[-2]\n",
    "    min_sequence_paths_val = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence_paths[-1]\n",
    "    sample = get_sample(min_sequence_path_test)\n",
    "    if sample != None:\n",
    "        save_h5py(f\"{drive_sequence_path}\", sample, h_test)\n",
    "    sample = get_sample(min_sequence_paths_val)\n",
    "\n",
    "    if sample != None:\n",
    "        save_h5py(f\"{drive_sequence_path}\", sample, h_val)\n",
    "    for i, min_sequence in enumerate(min_sequence_paths[:-2]):\n",
    "        if '.DS_Store ' in min_sequence or not os.path.isdir(main_dir+\"/\"+drive_sequence_path+'/'+min_sequence): continue\n",
    "        p = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence\n",
    "        sample = get_sample(p)\n",
    "        if sample != None:\n",
    "            save_h5py(f\"{drive_sequence_path}_{min_sequence}\", sample, h_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_test.close()\n",
    "h_train.close()\n",
    "h_val.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data on how much cruise state is enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7890547\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('gas_and_brake_train_comma_chunk_2_w_imgs.hfd5', \"r\") as f:\n",
    "    # Print all root level object names (aka keys) \n",
    "    # these can be group or dataset names \n",
    "    #     # get first object name/key; may or may NOT be a group\n",
    "    all_group_key = list(f.keys())\n",
    "    allcc = []\n",
    "    for a_group_key in all_group_key:\n",
    "    \n",
    "        data = list(f[a_group_key])\n",
    "        # preferred methods to get dataset values:\n",
    "        ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "        ds_arr = f[a_group_key]['dist'][()]\n",
    "        ds_arr = f[a_group_key]['CruiseStateenabled'][()].mean()\n",
    "        allcc.append(ds_arr)\n",
    "    print(np.array(allcc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80568177\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('gas_and_brake_val_comma_chunk_2_w_imgs.hfd5', \"r\") as f:\n",
    "    # Print all root level object names (aka keys) \n",
    "    # these can be group or dataset names \n",
    "    #     # get first object name/key; may or may NOT be a group\n",
    "    all_group_key = list(f.keys())\n",
    "    allcc = []\n",
    "    for a_group_key in all_group_key:\n",
    "    \n",
    "        data = list(f[a_group_key])\n",
    "        # preferred methods to get dataset values:\n",
    "        ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "        ds_arr = f[a_group_key]['dist'][()]\n",
    "        ds_arr = f[a_group_key]['CruiseStateenabled'][()].mean()\n",
    "        allcc.append(ds_arr)\n",
    "    print(np.array(allcc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71541667\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('gas_and_brake_test_comma_chunk_2_w_imgs.hfd5', \"r\") as f:\n",
    "    # Print all root level object names (aka keys) \n",
    "    # these can be group or dataset names \n",
    "    #     # get first object name/key; may or may NOT be a group\n",
    "    all_group_key = list(f.keys())\n",
    "    allcc = []\n",
    "    for a_group_key in all_group_key:\n",
    "    \n",
    "        data = list(f[a_group_key])\n",
    "        # preferred methods to get dataset values:\n",
    "        ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "        ds_arr = f[a_group_key]['dist'][()]\n",
    "        ds_arr = f[a_group_key]['CruiseStateenabled'][()].mean()\n",
    "        allcc.append(ds_arr)\n",
    "    print(np.array(allcc).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ba58c45dab89b2514588d38e9290524be89266c2f7a797ba911e1e9b00c0381"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
