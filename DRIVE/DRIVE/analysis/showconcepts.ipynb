{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------using concept datapath at:--- /hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock/scenarios/scenarios_small_100.txt\n",
      "torch.Size([100, 77])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc2hdd/home/tianlangxue/anaconda3/envs/OPT/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using img_noise\n",
      "current dataset: /hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data/comma_test_w_desired_filtered_GaussNoiseV2.h5py\n",
      "data_path----- /hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data/comma_test_w_desired_filtered_GaussNoiseV2.h5py -----------------\n",
      "using concept features\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import torch \n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"/hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock/analyse_results\")\n",
    "from vis_utils import * \n",
    "\n",
    "from utils import pad_collate\n",
    "from dataloader_comma import CommaDataset\n",
    "from dataloader_nuscenes import NUScenesDataset\n",
    "from collections import Counter\n",
    "from model import VTN\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "from utils import * \n",
    "import re\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using concept features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"/hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock\")\n",
    "from model import *\n",
    "from module import * \n",
    "# sys.path.append(\"/hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock/New\")\n",
    "# from model_copy1 import *\n",
    "# from model_copy2 import *\n",
    "# from module_copy1 import  *\n",
    "#define  pertubation and hyperparams\n",
    "img_noise =\"GaussNoiseV2\"\n",
    "multitask =\"multitask\"\n",
    "bs = 1\n",
    "dataset = \"comma\"\n",
    "backbone = \"none\"\n",
    "checkpoint_path = '/hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data/ckpts_final/ckpts_final_comma_multitask_none_True_1/lightning_logs/version_52_5loss/checkpoints/epoch=0-step=120.ckpt'\n",
    "model = VTN(multitask=multitask, backbone=backbone, concept_features=True, device = f\"cuda:0\", train_concepts=False)\n",
    "# teachmodel = TVTN(multitask=multitask, backbone=backbone, concept_features=True, device = f\"cuda:0\", train_concepts=False)\n",
    "testmodule = LaneModule.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    model=model,  # 传递模型参数\n",
    "    # teachmodel=teachmodel,\n",
    "    multitask=multitask,\n",
    "    dataset=dataset,\n",
    "    bs=bs,  # 传递批处理大小\n",
    "    ground_truth=\"desired\",\n",
    "    # intervention=args.intervention_prediction,\n",
    "    img_noise=img_noise,\n",
    "    # dataset_path=args.dataset_path,\n",
    "    # dataset_fraction=args.dataset_fraction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view the concepts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img noise: GaussNoiseV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:03, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 240, 1])\n",
      "torch.Size([1, 240, 1])\n",
      "----\n",
      "torch.Size([1, 240, 3, 224, 224])\n",
      "1\n",
      "torch.Size([1, 240, 100])\n",
      "Data saved to cleanDCGlogits_data.csv\n",
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "concs = []\n",
    "gt = []\n",
    "conc_list = []\n",
    "testmodule.to(f'cuda:0')\n",
    "print(\"img noise:\",commda_ds.img_noise)\n",
    "\n",
    "for j, batch in tqdm(enumerate(dataloader_comma)):\n",
    "    _, image_array, vego, angle, distance = batch\n",
    "    img = image_array\n",
    "    img, angle, distance, vego = img.to(f'cuda:0'), angle.to(f'cuda:0'), distance.to(f'cuda:0'), vego.to(f'cuda:0')\n",
    "    logits, attns, concepts = testmodule(img, angle, distance, vego)\n",
    "        # 将概念张量添加到列表中\n",
    "    conc_list.append(concepts.cpu())  # 移动回CPU并添加到列表\n",
    "\n",
    "    if j==0:\n",
    "        # print(logits)\n",
    "\n",
    "        print(logits[0].shape)\n",
    "        print(logits[1].shape)\n",
    "        print(\"----\")\n",
    "        print(img.shape)\n",
    "        print(len(concepts))\n",
    "        print(concepts.shape)\n",
    "        # 将张量数据转换为 DataFrame\n",
    "        logits_0_data = logits[0].detach().squeeze().cpu().numpy()  # 转换为 numpy 数组并移除多余的维度\n",
    "        logits_1_data = logits[1].detach().squeeze().cpu().numpy()  # 转换为 numpy 数组并移除多余的维度\n",
    "        angle_data =angle.detach().squeeze().cpu().numpy()\n",
    "        dist_data =distance.detach().squeeze().cpu().numpy()\n",
    "        df = pd.DataFrame({\n",
    "            'logits_0': logits_0_data.flatten(),\n",
    "            'logits_1': logits_1_data.flatten(),\n",
    "            'angle_gt':angle_data,\n",
    "            'dist_gt':dist_data\n",
    "        })\n",
    "\n",
    "        csv_file_path = 'cleanDCGlogits_data.csv'\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "        print(f\"Data saved to {csv_file_path}\")\n",
    "        break\n",
    "        \n",
    "\n",
    "\n",
    "# thisimg =(thisimg.astype(float)*255)\n",
    "# image = Image.fromarray(thisimg.astype('uint8'), 'RGB')\n",
    "# image.show()\n",
    "# conc_probs = torch.stack(conc_list)\n",
    "# print(conc_probs.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储concept_probs到文件\n",
    "torch.save(conc_probs, '/hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock/my_concept_probs/conc_probs_tensors/distance_concept_text10%altered.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate a wasserstein_distance between concepts data under different perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_tensor_from_file(file_path):\n",
    "    return torch.load(file_path)\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute the softmax of each element in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def calculate_EMD(distribution1, distribution2):\n",
    "    dist1_np = distribution1.cpu().numpy()\n",
    "    dist2_np = distribution2.cpu().numpy()\n",
    "    frame_num = dist1_np.shape[0]\n",
    "\n",
    "    # 计算并返回 EMD\n",
    "    mean_emd = 0\n",
    "    for frame in range(frame_num):\n",
    "        mean_emd += wasserstein_distance(softmax(dist1_np[frame]), softmax(dist2_np[frame]))\n",
    "    mean_emd /= frame_num\n",
    "    return mean_emd\n",
    "\n",
    "file_path1 = '/hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock/my_concept_probs/conc_probs_tensors/distance_concept_text10%altered.pt'  # 替换为第一个文件的路径\n",
    "file_path2 = '/hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock/my_concept_probs/conc_probs_tensors/multi_concept_text10%alterd.pt'  # 替换为第二个文件的路径\n",
    "\n",
    "probs1 = load_tensor_from_file(file_path1)\n",
    "probs2 = load_tensor_from_file(file_path2)\n",
    "\n",
    "probs1 = probs1.squeeze() \n",
    "probs2 = probs2.squeeze()\n",
    "\n",
    "\n",
    "probs1 = probs1.to(probs2.device)\n",
    "\n",
    "\n",
    "emd_values = []\n",
    "for i in range(probs1.size(0)):\n",
    "\n",
    "    emd = calculate_EMD(probs1[i], probs2[i])\n",
    "    emd_values.append(emd)\n",
    "\n",
    "# 打印结果\n",
    "print(f\"Earth Mover's Distance values for each sample: {emd_values}\")\n",
    "average_emd = np.mean(emd_values)\n",
    "print(f\"Average EMD: {average_emd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(probs1[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(softmax(probs1.cpu().numpy()[0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probs1-probs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name1 = file_path1.split('/')[-1]\n",
    "file_name2 = file_path2.split('/')[-1]\n",
    "output_file_path = '/hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock/my_concept_probs/conceptsmetrics/EWD.txt' \n",
    "with open(output_file_path, 'a') as f:\n",
    "    f.write(f\"conceptprobs 1: {file_name1}\\n\")\n",
    "    f.write(f\"conceptprobs 2: {file_name2}\\n\")\n",
    "    f.write(f\"EMD values for each sample: {emd_values}\\n\")\n",
    "    f.write(f\"Average EMD: {average_emd}\\n\")\n",
    "\n",
    "print(f\"EWD results have been saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
