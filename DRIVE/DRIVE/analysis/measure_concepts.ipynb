{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"/DRIVEcodeV1/DCG_Core\")\n",
    "sys.path.append(\"/your/dataset/path\")\n",
    "import pytorch_lightning as pl\n",
    "# from module_copy1 import *\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoints path& task setup\n",
    "\n",
    "task = \"angle\"#angle/distance/multitask ,align with version path\n",
    "version_path=\"/ckpt_final/../version1\"\n",
    "prediction_save_path =\"../predictions\"\n",
    "# text_save_rootpath =f\"/hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock/New/results/MAEtext/{task}_{os.path.basename(version_path)}.txt\"\n",
    "# ckpts_path =version_path+\"/checkpoints\"\n",
    "# ckpt_path_list = get_ckpt_files(ckpts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from model import *\n",
    "# from module import  *\n",
    "from module_copy1_only4conceptpredict import  *\n",
    "from model_copy1 import *\n",
    "from model_copy2 import *\n",
    "from main_copy1 import save_preds\n",
    "\n",
    "teachmodel=TVTN(multitask=task, backbone=\"none\", concept_features=True, device = f\"cuda:0\", train_concepts=False)\n",
    "model = VTN(multitask=task, backbone= \"none\", concept_features=True, device = f\"cuda:0\", train_concepts=False)\n",
    "# module = LaneModule(model=model,teachmodel=teachmodel, multitask=task, dataset = \"comma\", bs=2, ground_truth=\"normal\", intervention=False, img_noise=args.img_noise,dataset_path=args.dataset_path, dataset_fraction=args.dataset_fraction)\n",
    "# checkpoint = torch.load(ckpt_path_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testmodule.model.state_dict\n",
    "# testmodule.teachmodel.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_noise=None\n",
    "MAE_list=[]#save num of epochs mae results\n",
    "# os.makedirs(text_save_rootpath, exist_ok=True)\n",
    "# from dataloader_comma import *\n",
    "# if not os.path.exists(prediction_save_path):\n",
    "#     os.makedirs(prediction_save_path)\n",
    "gn1_DRIVE_ckpt_path= \"/hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data/ckpts_final/ckpts_final_comma_angle_none_True_1/lightning_logs/version_119_40epoch_5loss/checkpoints/epoch=34-step=4200_GNV1.ckpt\"\n",
    "gn1_DCG_ckpt_path =\"/hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data/ckpts_final/ckpts_final_comma_angle_none_True_1/lightning_logs/version_20_8.23/checkpoints/epoch=185-step=11160_GNV2.ckpt\"\n",
    "clean_DRIVE_ckpt_path= \"/hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data/ckpts_final/ckpts_final_comma_angle_none_True_1/lightning_logs/version_119_40epoch_5loss/checkpoints/epoch=34-step=4200.ckpt\"\n",
    "\n",
    "clean_DCG_ckpt_path=\"/hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data/ckpts_final/ckpts_final_comma_angle_none_True_1/lightning_logs/version_20_8.23/checkpoints/epoch=185-step=11160.ckpt\"\n",
    "# for id in tqdm(range(len(ckpt_path_list))):\n",
    "    \n",
    "# print(os.path.basename(ckpt_path_list[id]).split(\"-\")[0])\n",
    "\n",
    "# define modules using different inputs\n",
    "perturbed_module = LaneModule.load_from_checkpoint(\n",
    "    checkpoint_path=gn1_DRIVE_ckpt_path,\n",
    "    model=model, \n",
    "    teachmodel =teachmodel,\n",
    "    multitask=task,\n",
    "    dataset = \"comma\",\n",
    "    dataset_path=\"/hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data\",\n",
    "    bs=1,  \n",
    "    ground_truth=\"desired\",\n",
    "    # intervention=args.intervention_prediction,\n",
    "    img_noise=img_noise,\n",
    "    # dataset_path=args.dataset_path,\n",
    "    # dataset_fraction=args.dataset_fraction\n",
    "    )\n",
    "\n",
    "clean_module = LaneModule.load_from_checkpoint(\n",
    "    checkpoint_path=clean_DRIVE_ckpt_path,\n",
    "    model=model,\n",
    "    teachmodel =teachmodel, \n",
    "    multitask=task,\n",
    "    dataset = \"comma\",\n",
    "    dataset_path=\"/hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data\",\n",
    "    bs=1,  \n",
    "    ground_truth=\"desired\",\n",
    "    # intervention=args.intervention_prediction,\n",
    "    img_noise=None,\n",
    "    # dataset_path=args.dataset_path,\n",
    "    # dataset_fraction=args.dataset_fraction\n",
    "    )\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    accelerator='gpu',\n",
    "    devices=\"cuda:0\",\n",
    "\n",
    ")\n",
    "\n",
    "perturbedpreds =trainer.predict(perturbed_module)\n",
    "cleanpreds = trainer.predict(clean_module)\n",
    "# assert len(perturbedpreds) == len(cleanpreds), \"The lengths of perturbedpreds and cleanpreds should be the same.\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"DRIVE_ParamGNV1_top5overlap.txt\"\n",
    "\n",
    "total_overlap_rate = []\n",
    "with open(output_file, 'w') as file:\n",
    "    for cleanpred, ptbpred in zip(cleanpreds, perturbedpreds):\n",
    "        clean_concept = cleanpred[3]  \n",
    "        ptb_concept = ptbpred[3]      \n",
    "        \n",
    "\n",
    "        clean_top5_indices = torch.tensor(clean_concept.squeeze()).topk(5, dim=-1).indices  # size [240,5]\n",
    "    \n",
    "        ptb_top5_indices = torch.tensor(ptb_concept.squeeze()).topk(5, dim=-1).indices  # size [240,5]\n",
    "        print(clean_top5_indices.shape)\n",
    "        print(ptb_top5_indices.shape)\n",
    "        num_frames, top_k = clean_top5_indices.shape\n",
    "        frame_overlap_rates = []\n",
    "\n",
    "        frame_rates = []\n",
    "        print(range(num_frames))\n",
    "        for f in list(range(num_frames)):\n",
    "            print(clean_top5_indices[f].tolist())\n",
    "            clean_set = set(clean_top5_indices[f].tolist())\n",
    "            ptb_set = set(ptb_top5_indices[f].tolist())\n",
    "            overlap = len(clean_set.intersection(ptb_set))\n",
    "            total = min(len(clean_set), len(ptb_set))\n",
    "            if total > 0:\n",
    "                rate = overlap / total\n",
    "                frame_rates.append(rate)\n",
    "            else:\n",
    "                frame_rates.append(0.0)\n",
    "        frame_overlap_rates.append(frame_rates)  \n",
    "\n",
    "     \n",
    "        avg_frame_overlap_rate = [sum(frame_rate) / len(frame_rate) for frame_rate in frame_overlap_rates]\n",
    "\n",
    "    \n",
    "        total_overlap_rate.extend(avg_frame_overlap_rate)\n",
    "\n",
    "        file.write(f\"Sample average overlap rates: {avg_frame_overlap_rate}\\n\")\n",
    "\n",
    "    if total_overlap_rate:\n",
    "        overall_avg_overlap_rate = sum(total_overlap_rate) / len(total_overlap_rate)\n",
    "    else:\n",
    "        overall_avg_overlap_rate = 0.0\n",
    "    file.write(f\"Overall average overlap rate: {overall_avg_overlap_rate}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
