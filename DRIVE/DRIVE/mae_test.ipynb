{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtain module predictions CSV file& calculate MAE (preds,gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc2hdd/home/tianlangxue/anaconda3/envs/OPT/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------using concept datapath at:--- /hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock/scenarios/scenarios_small_100.txt\n",
      "torch.Size([100, 77])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"/DRIVEcodeV1/DCG_Core\")\n",
    "sys.path.append(\"your/dataset/path\")\n",
    "import pytorch_lightning as pl\n",
    "from model import *\n",
    "from module import  *\n",
    "# from module_copy1 import *\n",
    "# from model_copy1 import *\n",
    "# from model_copy2 import *\n",
    "# from main_copy1 import save_preds\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def calculate_mae(actual, predicted):\n",
    "    return ((actual - predicted).abs()).mean()\n",
    "\n",
    "# 读取 CSV 文件\n",
    "def read_csv_file(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# 写入文件名和 MAE 到文本文件\n",
    "def write_to_txt_file(txt_file_path, file_name, mae_value):\n",
    "    try:\n",
    "        with open(txt_file_path, 'a') as file:\n",
    "            file.write(f\"{file_name},{mae_value}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write to {txt_file_path}: {e}\")\n",
    "        \n",
    "def calculate_save_MAE(csvpathlist,textpath,task):\n",
    "    \n",
    "    thisbranch_MAE=[]\n",
    "    txt_file_path = textpath  \n",
    "    \n",
    "    for csv_file_path in csvpathlist: \n",
    "\n",
    "        df = read_csv_file(csv_file_path)\n",
    "        \n",
    "        if df.shape[1] < 2:\n",
    "            raise ValueError(\"CSV must contains 2 columns。\")\n",
    "\n",
    "        actual_values = df.iloc[:, 1]\n",
    "        predicted_values = df.iloc[:, 0]\n",
    "\n",
    "        mae = calculate_mae(actual_values, predicted_values)\n",
    "        \n",
    "        if task == \"multitask\":\n",
    "            if \"angle\" in csv_file_path:\n",
    "                txt_file_path = f\"/your/analysis/record/angle_{task}_{img_noise}.txt\"\n",
    "            elif \"dist\" in csv_file_path:\n",
    "                txt_file_path = f\"/your/analysis/record/distance_{task}_{img_noise}.txt\"\n",
    "        else: txt_file_path = f\"/your/analysis/record/{task}_{img_noise}.txt\"\n",
    "     \n",
    "        file_name = csv_file_path.split('/')[-1]\n",
    "     \n",
    "        # print(f\"MAE for {file_name}: {mae}\")\n",
    "   \n",
    "        write_to_txt_file(txt_file_path, file_name, mae)\n",
    "        thisbranch_MAE.append(mae)#a list containing 1 or 2 values(single/multi-task)\n",
    "    return thisbranch_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoints path& task setup\n",
    "img_noise=\"GaussNoiseV3\"\n",
    "task = \"multitask\"#angle/distance/multitask ,align with version path\n",
    "checkpoint =\"/hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data/ckpts_final/ckpts_final_comma_multitask_none_True_1/lightning_logs/version_19_testval_noreverse/checkpoints/epoch=143-step=8640.ckpt\"\n",
    "# ckpts_path =version_path+\"/checkpoints\"\n",
    "# ckpt_path_list = get_ckpt_files(ckpts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using concept features\n"
     ]
    }
   ],
   "source": [
    "# teachmodel=TVTN(multitask=task, backbone=\"none\", concept_features=True, device = f\"cuda:0\", train_concepts=False)\n",
    "model = VTN(multitask=task, backbone= \"none\", concept_features=True, device = f\"cuda:0\", train_concepts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preds(logits, target, save_name, p):\n",
    "    b, s = target.shape\n",
    "    df = pd.DataFrame()\n",
    "    df['logits'] = logits.squeeze().reshape(b*s).tolist()\n",
    "    df['target'] = target.squeeze().reshape(b*s).tolist()\n",
    "    directory = os.path.dirname(f'{p}/{save_name}.csv')\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    df.to_csv(f'{p}/{save_name}.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc2hdd/home/tianlangxue/anaconda3/envs/OPT/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "/hpc2hdd/home/tianlangxue/anaconda3/envs/OPT/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:498: UserWarning: The flag `devices=cuda:0` will be ignored, instead the device specific number 1 will be used\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2024-09-14 23:27:29.237251: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-14 23:27:29.252503: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-14 23:27:29.267815: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-14 23:27:29.271996: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-14 23:27:29.285199: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-14 23:27:30.944511: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using img_noise\n",
      "current dataset: /hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data/comma_test_w_desired_filtered_GaussNoiseV3.h5py\n",
      "data_path----- /hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data/comma_test_w_desired_filtered_GaussNoiseV3.h5py -----------------\n",
      "Predicting DataLoader 0: 100%|██████████| 27/27 [00:10<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "MAE_list=[]#save num of epochs mae results\n",
    "# os.makedirs(text_save_rootpath, exist_ok=True)\n",
    "\n",
    "testmodule = LaneModule.load_from_checkpoint(\n",
    "checkpoint,\n",
    "model=model,  # 传递模型参数\n",
    "# teachmodel =teachmodel,\n",
    "multitask=task,\n",
    "dataset = \"comma\",\n",
    "dataset_path=\"/hpc2hdd/home/tianlangxue/XAI4AD/comma2k19data\",\n",
    "bs=1,  # 传递批处理大小\n",
    "ground_truth=\"desired\",\n",
    "# intervention=args.intervention_prediction,\n",
    "img_noise=img_noise,\n",
    "# dataset_path=args.dataset_path,\n",
    "# dataset_fraction=args.dataset_fraction\n",
    ")\n",
    "# 定义Trainer用于预测\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    accelerator='gpu',\n",
    "    devices=\"cuda:0\",\n",
    "    # logger=logger,\n",
    "    # default_root_dir=ckpt_pth,  # 这个参数可以用来指定默认的输出目录\n",
    "    # resume_from_checkpoint=checkpoint_path,  # 如果需要从特定的检查点恢复\n",
    "    # 注：resume_from_checkpoint在预测时不常用，因为我们通常直接load_model来预测\n",
    ")\n",
    "\n",
    "preds = trainer.predict(testmodule)\n",
    "#save logits into csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['/hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock/New/DCGPreds/single_distance_DRIVE_100scenarios_GaussNoiseV3.csv']\n"
     ]
    }
   ],
   "source": [
    "prediction_save_path =\"/hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock/New/DCGPreds\"\n",
    "text_save_rootpath=\"/hpc2hdd/home/tianlangxue/XAI4AD/concept_gridlock/New/DCGMAE\"\n",
    "csvp=set()\n",
    "print(len(preds))\n",
    "assert len(preds) >= 3, \"pred must have at least three elements\"\n",
    "for pred in preds:\n",
    "    if task != \"multitask\":\n",
    "        predictions, preds_1, preds_2 = pred[0], pred[1], pred[2] \n",
    "        save_preds(predictions, preds_1, f\"single_{task}_DRIVE_100scenarios_{img_noise}\", prediction_save_path)#DRIVE=concept\n",
    "        csvp.add(prediction_save_path+f\"/single_{task}_DRIVE_100scenarios_{img_noise}.csv\")\n",
    "    else:\n",
    "        preds, angle, dist = pred[0], pred[1], pred[2]\n",
    "        preds_angle, preds_dist = preds[0], preds[1]\n",
    "        # print(preds_angle.shape,preds_dist.shape)\n",
    "        # print(angle.shape,dist.shape)\n",
    "        save_preds(preds_angle, angle, f\"angle_multi_{task}_DRIVE_100scenarios_{img_noise}\", prediction_save_path)\n",
    "        save_preds(preds_dist, dist, f\"dist_multi_{task}_DRIVE_100scenarios_{img_noise}\", prediction_save_path)\n",
    "        csvp.add(prediction_save_path+f\"/angle_multi_{task}_DRIVE_100scenarios_{img_noise}.csv\")\n",
    "        csvp.add((prediction_save_path+f\"/dist_multi_{task}_DRIVE_100scenarios_{img_noise}.csv\"))\n",
    "csvp =list(csvp)\n",
    "print(csvp)\n",
    "MAE_list.append(calculate_save_MAE(csvp,text_save_rootpath,task))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
